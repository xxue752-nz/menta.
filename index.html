<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Menta: A Small Language Model for On-Device Mental Health Prediction</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="description" content="Menta: A Small Language Model for On-Device Mental Health Prediction" />
  <style>
    :root {
      --bg: #f7f8fc;
      --bg-top: #0b1f4a;
      --accent: #2563eb;
      --accent-soft: #e0edff;
      --text-main: #111827;
      --text-sub: #4b5563;
      --card-bg: #ffffff;
      --border: #e5e7eb;
      --radius: 18px;
      --shadow: 0 14px 35px rgba(15, 23, 42, 0.12);
      --max-width: 960px;
    }

    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
    }

    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "SF Pro Text",
        "Segoe UI", sans-serif;
      background: var(--bg);
      color: var(--text-main);
      line-height: 1.6;
    }

    a {
      color: var(--accent);
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    /* é¡¶éƒ¨è“è‰²æ¡ */
    .site-header {
      background: linear-gradient(135deg, #111827, #1e3a8a);
      color: #e5e7eb;
      padding: 16px 16px;
    }

    .site-header-inner {
      max-width: var(--max-width);
      margin: 0 auto;
      display: flex;
      justify-content: space-between;
      align-items: center;
      gap: 12px;
    }

    .site-title {
      font-size: 1.1rem;
      font-weight: 700;
    }

    .site-nav {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      font-size: 0.9rem;
    }

    .site-nav a {
      color: #e5e7eb;
      padding: 4px 10px;
      border-radius: 999px;
      background: rgba(15, 23, 42, 0.2);
    }

    .site-nav a:hover {
      background: rgba(15, 23, 42, 0.4);
      text-decoration: none;
    }

    /* é¡µé¢ä¸»ä½“ */
    .page {
      max-width: var(--max-width);
      margin: 26px auto 40px;
      padding: 0 16px 40px;
    }

    /* hero åŒºåŸŸ */
    .hero {
      background: var(--card-bg);
      border-radius: 24px;
      padding: 22px 20px 18px;
      box-shadow: var(--shadow);
      border: 1px solid rgba(148, 163, 184, 0.4);
      position: relative;
      overflow: hidden;
    }

    .hero::before {
      content: "";
      position: absolute;
      inset: -120px;
      background: radial-gradient(circle at top right,
        rgba(37, 99, 235, 0.26),
        transparent 55%);
      pointer-events: none;
    }

    .hero-inner {
      position: relative;
      display: grid;
      grid-template-columns: minmax(0, 3fr) minmax(0, 2fr);
      gap: 20px;
      align-items: center;
    }

    @media (max-width: 840px) {
      .hero-inner {
        grid-template-columns: minmax(0, 1fr);
      }
    }

    .tagline {
      display: inline-flex;
      align-items: center;
      gap: 6px;
      font-size: 0.8rem;
      padding: 3px 9px;
      border-radius: 999px;
      background: rgba(15, 23, 42, 0.06);
      color: var(--text-sub);
      margin-bottom: 8px;
    }

    .tagline-dot {
      width: 8px;
      height: 8px;
      border-radius: 999px;
      background: #22c55e;
      box-shadow: 0 0 0 4px rgba(34, 197, 94, 0.35);
    }

    .title {
      font-size: 2rem;
      line-height: 1.15;
      letter-spacing: -0.03em;
      margin-bottom: 10px;
    }

    .subtitle {
      font-size: 0.98rem;
      color: var(--text-sub);
      max-width: 540px;
      margin-bottom: 14px;
    }

    .btn-row {
      display: flex;
      flex-wrap: wrap;
      gap: 8px;
      margin-bottom: 10px;
    }

    .btn {
      display: inline-flex;
      align-items: center;
      gap: 6px;
      padding: 7px 13px;
      border-radius: 999px;
      font-size: 0.9rem;
      border: 1px solid rgba(148, 163, 184, 0.7);
      background: rgba(249, 250, 251, 0.8);
      color: var(--text-main);
      text-decoration: none;
      cursor: pointer;
      transition: all 0.15s;
      backdrop-filter: blur(4px);
    }

    .btn span.icon {
      font-size: 1.05rem;
    }

    .btn-primary {
      background: linear-gradient(135deg, #2563eb, #4f46e5);
      border-color: transparent;
      color: white;
      box-shadow: 0 10px 26px rgba(37, 99, 235, 0.45);
    }

    .btn:hover {
      transform: translateY(-1px);
      box-shadow: 0 10px 24px rgba(15, 23, 42, 0.16);
      text-decoration: none;
    }

    .hero-meta {
      font-size: 0.8rem;
      color: var(--text-sub);
    }

    .authors-block {
      margin-top: 16px;
      font-size: 0.88rem;
    }

    .authors-line {
      display: flex;
      flex-wrap: wrap;
      gap: 10px;
      margin-bottom: 4px;
    }

    .author-name sup {
      font-size: 0.6rem;
      margin-left: 1px;
    }

    .affiliations {
      font-size: 0.82rem;
      color: var(--text-sub);
    }

    .email-note {
      margin-top: 4px;
      font-size: 0.8rem;
      color: var(--text-sub);
    }

    .hero-side-card {
      background: rgba(15, 23, 42, 0.88);
      color: #e5e7eb;
      border-radius: 18px;
      padding: 14px 14px 12px;
      font-size: 0.85rem;
      box-shadow: 0 18px 40px rgba(15, 23, 42, 0.6);
    }

    .hero-side-title {
      font-size: 0.92rem;
      font-weight: 600;
      margin-bottom: 4px;
      color: #e0ecff;
    }

    .pill-row {
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
      margin-top: 6px;
    }

    .pill {
      padding: 3px 9px;
      border-radius: 999px;
      border: 1px solid rgba(148, 163, 184, 0.5);
      background: rgba(15, 23, 42, 0.4);
      font-size: 0.75rem;
    }

    /* ä¸»ä½“ section */
    main {
      margin-top: 28px;
      display: grid;
      grid-template-columns: minmax(0, 2.2fr) minmax(0, 1.5fr);
      gap: 20px;
    }

    @media (max-width: 840px) {
      main {
        grid-template-columns: minmax(0, 1fr);
      }
    }

    section {
      margin-bottom: 18px;
    }

    .card {
      background: var(--card-bg);
      border-radius: var(--radius);
      padding: 16px 16px 14px;
      border: 1px solid var(--border);
      box-shadow: 0 6px 16px rgba(15, 23, 42, 0.06);
    }

    .card h2 {
      font-size: 1.02rem;
      margin-bottom: 6px;
    }

    .card h3 {
      font-size: 0.95rem;
      margin: 8px 0 4px;
    }

    .card p {
      font-size: 0.9rem;
      color: var(--text-sub);
      margin-bottom: 6px;
    }

    .card ul {
      margin-left: 18px;
      font-size: 0.9rem;
      color: var(--text-sub);
    }

    .card li {
      margin-bottom: 4px;
    }

    .badge-row {
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
      margin: 4px 0 6px;
    }

    .badge {
      font-size: 0.75rem;
      padding: 3px 8px;
      border-radius: 999px;
      background: var(--accent-soft);
      color: #1d4ed8;
      border: 1px solid rgba(129, 140, 248, 0.6);
    }

    .dataset-table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.82rem;
      margin-top: 6px;
    }

    .dataset-table th,
    .dataset-table td {
      border: 1px solid var(--border);
      padding: 4px 6px;
      text-align: left;
    }

    .dataset-table th {
      background: #f3f4ff;
      font-weight: 600;
    }

    .highlight {
      margin-top: 6px;
      font-size: 0.85rem;
      background: var(--accent-soft);
      border-radius: 10px;
      padding: 6px 8px;
    }

    pre {
      background: #020617;
      color: #e5e7eb;
      padding: 10px 12px;
      border-radius: 12px;
      overflow-x: auto;
      font-size: 0.8rem;
      border: 1px solid rgba(30, 64, 175, 0.8);
    }

    code {
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas,
        "Liberation Mono", "Courier New", monospace;
    }

    footer {
      margin-top: 26px;
      padding-top: 14px;
      border-top: 1px solid var(--border);
      font-size: 0.8rem;
      color: var(--text-sub);
      display: flex;
      justify-content: space-between;
      gap: 10px;
      flex-wrap: wrap;
    }

    html {
      scroll-behavior: smooth;
    }
  </style>
</head>
<body>
  <!-- é¡¶éƒ¨è“æ¡ -->
  <header class="site-header">
    <div class="site-header-inner">
      <div class="site-title">menta â€“ website</div>
      <nav class="site-nav">
        <a href="#abstract">Abstract</a>
        <a href="#model">Model</a>
        <a href="#datasets">Datasets</a>
        <a href="#results">Results</a>
        <a href="#deployment">On-device</a>
        <a href="#bibtex">BibTeX</a>
      </nav>
    </div>
  </header>

  <div class="page">
    <!-- é¡¶éƒ¨ hero -->
    <section class="hero">
      <div class="hero-inner">
        <div>
          <div class="tagline">
            <span class="tagline-dot"></span>
            <span>Small Language Model Â· Mental Health Â· On-Device</span>
          </div>

          <h1 class="title">
            Menta: A Small Language Model<br />
            for On-Device Mental Health Prediction
          </h1>

          <p class="subtitle">
            Menta is a 4B-parameter small language model jointly trained on multiple
            social-media mental health tasks for stress, depression, and suicidality.
            It is designed to run entirely on consumer devices for privacy-preserving,
            real-time digital mental health screening.
          </p>

          <div class="btn-row">
            <!-- TODO: æŠŠä¸‹é¢å‡ ä¸ªé“¾æ¥çš„ href="#" æ”¹æˆçœŸå®åœ°å€ -->
            <a class="btn btn-primary" href="#" target="_blank" rel="noopener">
              <span class="icon">ğŸ“„</span><span>Paper PDF</span>
            </a>
            <a class="btn" href="#" target="_blank" rel="noopener">
              <span class="icon">ğŸ’»</span><span>Code</span>
            </a>
            <a class="btn" href="#" target="_blank" rel="noopener">
              <span class="icon">ğŸ“¦</span><span>Model / Weights</span>
            </a>
            <a class="btn" href="#" target="_blank" rel="noopener">
              <span class="icon">ğŸ“±</span><span>iOS Demo</span>
            </a>
          </div>

          <div class="hero-meta">
            <strong>Preprint</strong>, 2025. &nbsp;
            <!-- è¿™é‡Œå¯ä»¥æ¢æˆ UbiComp / IMWUT ç­‰æœ€ç»ˆæ¥æ”¶ä¿¡æ¯ -->
          </div>

          <div class="authors-block">
            <div class="authors-line">
              <span class="author-name">Tianyi Zhang<sup>1</sup></span>
              <span class="author-name">Xiangyuan Xue<sup>2</sup></span>
              <span class="author-name">Lingyan Ruan<sup>1</sup></span>
              <span class="author-name">Shiya Fu<sup>1</sup></span>
              <span class="author-name">Feng Xia<sup>3</sup></span>
              <span class="author-name">Simon D'Alfonso<sup>1</sup></span>
              <span class="author-name">Vassilis Kostakos<sup>1</sup></span>
              <span class="author-name">Ting Dang<sup>1</sup></span>
              <span class="author-name">Hong Jia<sup>2</sup></span>
            </div>
            <div class="affiliations">
              <sup>1</sup> The University of Melbourne, Australia Â·
              <sup>2</sup> The University of Auckland, New&nbsp;Zealand Â·
              <sup>3</sup> RMIT University, Australia
            </div>
            <div class="email-note">
              Contact:
              <a href="mailto:t.zhang59@student.unimelb.edu.au">t.zhang59@student.unimelb.edu.au</a>,
              <a href="mailto:xxue752@aucklanduni.ac.nz">xxue752@aucklanduni.ac.nz</a>,
              <a href="mailto:hong.jia@auckland.ac.nz">hong.jia@auckland.ac.nz</a>
            </div>
          </div>
        </div>

        <div>
          <div class="hero-side-card">
            <div class="hero-side-title">Menta at a glance</div>
            <p>
              â€¢ 4B-parameter small language model (Qwen-style backbone)<br />
              â€¢ LoRA-based multi-task training on six Reddit mental health tasks<br />
              â€¢ Balanced accuracyâ€“aware objective to handle severe class imbalance<br />
              â€¢ Ready for on-device deployment with 4-bit quantization
            </p>
            <div class="pill-row">
              <span class="pill">4B SLM</span>
              <span class="pill">Multi-task</span>
              <span class="pill">LoRA</span>
              <span class="pill">Balanced Acc.</span>
              <span class="pill">On-device</span>
            </div>
          </div>
        </div>
      </div>
    </section>

    <!-- ä¸»ä½“å†…å®¹ -->
    <main>
      <div>
        <!-- Abstract -->
        <section id="abstract" class="card">
          <h2>Abstract</h2>
          <p>
            Menta is a small language model for digital mental health prediction
            from social media text. It targets early detection of stress, depression,
            and suicidality while remaining lightweight enough to run entirely on
            consumer devices. By jointly training on multiple expert-annotated
            Reddit datasets and optimizing a balanced accuracyâ€“aware loss, Menta
            achieves competitive or superior performance compared with larger
            mental-healthâ€“tuned LLMs, and can be deployed for real-time,
            privacy-preserving on-device screening.
          </p>
          <!-- ä½ å¯ä»¥æŠŠä¸Šé¢è¿™ä¸€æ®µæ›¿æ¢æˆè®ºæ–‡é‡Œæ­£å¼çš„ abstract æ–‡æœ¬ -->
        </section>

        <!-- Model & Training -->
        <section id="model" class="card">
          <h2>Menta Model and Training</h2>
          <p>
            Menta is built on top of a 4B-parameter small language model and
            fine-tuned with parameter-efficient LoRA adapters for multi-task mental
            health prediction.
          </p>
          <div class="badge-row">
            <span class="badge">4B SLM backbone</span>
            <span class="badge">LoRA adapters</span>
            <span class="badge">Multi-task head</span>
            <span class="badge">Balanced accuracy loss</span>
          </div>
          <ul>
            <li>
              A shared transformer backbone with task-specific classification heads.
            </li>
            <li>
              LoRA adapters applied to attention projections, keeping most base
              parameters frozen and reducing GPU memory cost.
            </li>
            <li>
              Joint training across six tasks with task sampling to manage dataset
              size imbalance.
            </li>
            <li>
              Loss combines class-weighted cross-entropy and a differentiable
              surrogate for balanced accuracy to handle label imbalance.
            </li>
          </ul>
        </section>

        <!-- Results -->
        <section id="results" class="card">
          <h2>Evaluation and Results</h2>
          <p>
            We compare Menta with a range of small language models under zero-shot
            and few-shot prompting, as well as larger mental-healthâ€“tuned LLM baselines.
          </p>
          <ul>
            <li>
              Menta consistently outperforms non-finetuned SLMs across all six tasks.
            </li>
            <li>
              On depression and stress prediction, Menta is competitive with or
              better than 13B mental-healthâ€“tuned LLMs.
            </li>
            <li>
              The 4B model is substantially smaller and more suitable for mobile
              deployment than 13B LLMs.
            </li>
          </ul>
          <p class="highlight">
            TODO: åœ¨è¿™é‡Œæ’å…¥ç»“æœå›¾æˆ–è¡¨æ ¼ã€‚<br />
            ä½¿ç”¨æ–¹æ³•ï¼šå…ˆæŠŠå›¾ç‰‡ä¸Šä¼ åˆ°ä»“åº“çš„ <code>images/</code> ç›®å½•ï¼Œä¾‹å¦‚
            <code>results.png</code>ï¼Œç„¶ååœ¨è¿™é‡ŒåŠ ä¸€è¡Œï¼š<br />
            <code>&lt;img src="images/results.png" alt="Results" style="width:100%;max-width:720px;border-radius:12px;margin-top:6px;" /&gt;</code>
          </p>
        </section>
      </div>

      <!-- å³ä¾§æ  -->
      <div>
        <!-- Datasets -->
        <section id="datasets" class="card">
          <h2>Datasets</h2>
          <p>
            We train and evaluate Menta on four expert-annotated Reddit corpora,
            organized into six classification tasks:
          </p>
          <table class="dataset-table">
            <thead>
              <tr>
                <th>Task</th>
                <th>Dataset</th>
                <th>Label type</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>Task 1</td>
                <td>Dreaddit</td>
                <td>Stress vs. non-stress</td>
              </tr>
              <tr>
                <td>Task 2â€“3</td>
                <td>Depression severity</td>
                <td>Binary depression + severity levels</td>
              </tr>
              <tr>
                <td>Task 4</td>
                <td>SDCNL</td>
                <td>Suicidal ideation vs. non-ideation</td>
              </tr>
              <tr>
                <td>Task 5â€“6</td>
                <td>CSSRS-based suicide risk</td>
                <td>Binary risk + multi-level risk categories</td>
              </tr>
            </tbody>
          </table>
          <p class="highlight">
            TODO: å¯ä»¥åœ¨è¿™é‡Œè¿½åŠ æ¯ä¸ªæ•°æ®é›†çš„é“¾æ¥ï¼ˆåŸè®ºæ–‡ / å®˜æ–¹ repoï¼‰ä»¥åŠæ ·æœ¬é‡ã€ä¼¦ç†
            è¯´æ˜ç­‰ã€‚
          </p>
        </section>

        <!-- On-device -->
        <section id="deployment" class="card">
          <h2>On-Device Deployment</h2>
          <p>
            We deploy Menta on mobile devices using a lightweight inference stack
            with quantized weights.
          </p>
          <ul>
            <li>4-bit GGUF quantization to reduce memory footprint.</li>
            <li>Inference via <code>llama.cpp</code> with Metal acceleration.</li>
            <li>Demonstrated on iPhone 15 Pro Max with real-time latency.</li>
            <li>All processing is local to the device for privacy-preserving screening.</li>
          </ul>
          <p class="highlight">
            TODO: å¯ä»¥æ”¾ 1â€“2 å¼  app æˆªå›¾ï¼ˆä¾‹å¦‚ <code>images/ios_demo.png</code>ï¼‰ï¼Œå¹¶åœ¨è¿™é‡Œå†™
            ä½¿ç”¨è¯´æ˜æˆ–æŒ‡å‘ GitHub READMEã€‚
          </p>
        </section>

        <!-- BibTeX -->
        <section id="bibtex" class="card">
          <h2>BibTeX</h2>
          <p>Use the following entry to cite Menta (update once the venue is fixed):</p>
          <pre><code>@article{menta2025,
  title   = {Menta: A Small Language Model for On-Device Mental Health Prediction},
  author  = {Zhang, Tianyi and Xue, Xiangyuan and Ruan, Lingyan
             and Fu, Shiya and Xia, Feng and D'Alfonso, Simon
             and Kostakos, Vassilis and Dang, Ting and Jia, Hong},
  journal = {TODO: venue},
  year    = {2025},
  note    = {Preprint}
}</code></pre>
        </section>
      </div>
    </main>

    <footer>
      <span>Â© 2025 Menta Authors.</span>
      <span>
        Code and models for research use only. Please see the repository for license details.
      </span>
    </footer>
  </div>
</body>
</html>
