---
layout: default
title: Menta
---

# Menta: A Small Language Model for On-Device Mental Health Prediction

Tianyi Zhang^1, Xiangyuan Xue^2, Lingyan Ruan^1,  
Shiya Fu^1, Feng Xia^3, Simon D'Alfonso^1,  
Vassilis Kostakos^1, Ting Dang^1, Hong Jia^2  

^1 The University of Melbourne, Australia  
^2 The University of Auckland, New Zealand  
^3 RMIT University, Australia  

[Paper](#) · [Code](#) · [Dataset](#) · [iOS Demo](#)

> **TODO：**
> - 上面四个链接里的 `#` 换成你的真实链接（arXiv / PDF / GitHub / HF / App 等）
> - 如果你们有 equal contribution，可以自己在名字后面加 `*`

---

## Abstract

*TODO: 把你论文里的 abstract 粘过来（英文），这里先放一个占位版本。*

Menta is a small language model designed for digital mental health prediction from
social media text. It targets early detection of stress, depression, and suicidality
while remaining lightweight enough to run entirely on consumer devices. By jointly
training multiple classification tasks on several expert-annotated Reddit datasets,
Menta achieves competitive or superior performance compared with larger mental-health–
tuned LLMs, and can be deployed for real-time, privacy-preserving on-device screening.

---

## Menta Model and Training

Menta is built on top of a 4B-parameter small language model and fine-tuned with
parameter-efficient LoRA adapters for multi-task mental health prediction.

- Small language model backbone (4B parameters).  
- LoRA-based multi-task finetuning with a shared backbone and task-specific heads.  
- Class-imbalance handling with class-weighted loss and balanced-accuracy–aware
  optimization.  
- Joint training across multiple Reddit-based datasets (stress, depression,
  suicidal ideation, suicide risk).

> **TODO：** 把这里改成和你们论文里模型结构 + training setup 对应的描述（层数、backbone 名称、LoRA 设置等）。

---

## Datasets

We train and evaluate Menta on four expert-annotated Reddit corpora, organized into
six classification tasks:

- **Dreaddit** – Stress vs. non-stress.  
- **Depression severity dataset** – Binary depression detection and multi-level
  severity prediction.  
- **SDCNL** – Suicidal ideation vs. non-ideation.  
- **C-SSRS–based suicide risk dataset** – Binary risk and multi-level suicide risk
  categories.

> **TODO：**
> - 可以在这里补充每个数据集的样本数、标签分布等。
> - 如果有公开链接（比如到原论文 / 数据集主页），可以用 Markdown 链接加上去。

---

## Evaluation and Results

We compare Menta with:

- Prompted small language models without mental health finetuning.  
- Larger mental-health–tuned LLMs (e.g., 13B-level models).  

Key findings include:

- Menta consistently outperforms non-finetuned SLMs on all six tasks.  
- On depression and stress prediction, Menta is competitive with or better than
  13B mental-health–tuned LLMs.  
- Menta is much smaller and more suitable for mobile deployment.

> **TODO：**
> - 可以在这里插入一张结果图，例如 ACC/BACC 柱状图或表格截图。  
> - 先把图片（例如 `results.png`）上传到仓库的 `images/` 目录，然后在这里写：
>   `![Results](images/results.png)`

---

## On-Device Deployment

We deploy Menta on mobile devices using a lightweight inference stack:

- Quantized weights (e.g., 4-bit GGUF) for reduced memory footprint.  
- Inference engine based on `llama.cpp` or a similar library.  
- On an iPhone 15 Pro Max, Menta can run in real time with acceptable latency
  and memory usage.

This enables privacy-preserving screening directly on user devices, without sending
raw text to remote servers.

> **TODO：**
> - 把这里改成你们真实的 on-device 部署细节（设备型号、量化配置、TTFT/吞吐、内存占用等）
> - 可以再插 1–2 张 app 截图，用：
>   `![iOS demo](images/ios_demo.png)`

---

## Implementation and Resources

- **Code**: TODO – link to your main GitHub repository for training and evaluation.  
- **Model weights**: TODO – link to HF or other hosting if you plan to release.  
- **Mobile app / demo**: TODO – link to your iOS/Android test app or demo video.  

> 建议在你的代码仓库里准备一个 `README`，和这里互相链接。

---

## BibTeX

```bibtex
@article{menta2025,
  title   = {Menta: A Small Language Model for On-Device Mental Health Prediction},
  author  = {Zhang, Tianyi and Xue, Xiangyuan and Ruan, Lingyan
             and Fu, Shiya and Xia, Feng and D'Alfonso, Simon
             and Kostakos, Vassilis and Dang, Ting and Jia, Hong},
  journal = {TODO: venue},
  year    = {2025},
  note    = {Preprint}
}
