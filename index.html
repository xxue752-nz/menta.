<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Menta: A Small Language Model for On-Device Mental Health Prediction</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="description" content="Menta: A Small Language Model for On-Device Mental Health Prediction" />
  <style>
    :root {
      --bg-from: #d8f1ea;
      --bg-to:   #c0e4df;
      --text-main: #111827;
      --text-sub:  #4b5563;
      --card-bg:   #ffffff;
      --border:    #e5e7eb;
      --max-width: 960px;

      --btn-bg:    #c9ded7;
      --btn-border:#90a6a0;
    }

    * {
      box-sizing: border-box;
      margin: 0;
      padding: 0;
    }

    body {
      font-family: system-ui, -apple-system, BlinkMacSystemFont, "SF Pro Text",
                   "Segoe UI", sans-serif;
      background: radial-gradient(circle at top left,
                  var(--bg-from) 0, var(--bg-to) 60%, #bcded7 100%);
      color: var(--text-main);
      line-height: 1.6;
    }

    a {
      color: inherit;
      text-decoration: none;
    }

    a:hover {
      text-decoration: underline;
    }

    /* ---------- HERO：顶部区域，仿 Web2Code ---------- */
    .hero {
      min-height: 260px;
      display: flex;
      flex-direction: column;
      align-items: center;
      text-align: center;
      padding: 60px 16px 40px;
    }

    .hero-inner {
      max-width: var(--max-width);
      width: 100%;
      margin: 0 auto;
    }

    h1.title {
      font-size: clamp(2.6rem, 4vw, 3.2rem);
      margin-bottom: 18px;
      font-weight: 700;
    }

    .authors {
      font-size: 0.95rem;
      color: var(--text-main);
      margin-bottom: 6px;
    }

    .affiliations {
      font-size: 0.85rem;
      color: var(--text-sub);
      margin-bottom: 28px;
    }

    .btn-row {
      display: flex;
      justify-content: center;
      flex-wrap: wrap;
      gap: 24px;
    }

    .link-btn {
      display: inline-flex;
      align-items: center;
      gap: 8px;
      padding: 12px 30px;
      min-width: 160px;
      justify-content: center;
      border-radius: 14px;
      background: var(--btn-bg);
      border: 1px solid var(--btn-border);
      box-shadow: 0 6px 14px rgba(15, 23, 42, 0.16);
      font-size: 1rem;
      color: #111827;
      transition:
        transform 0.15s ease,
        box-shadow 0.15s ease,
        background 0.15s ease,
        border-color 0.15s ease;
      text-decoration: none;
    }

    .link-btn:hover {
      transform: translateY(-2px);
      box-shadow: 0 10px 22px rgba(15, 23, 42, 0.22);
      background: #d6e9e3;
      border-color: #7f9992;
      text-decoration: none;
    }

    .link-icon {
      font-size: 1.3rem;
      display: inline-flex;
      align-items: center;
      justify-content: center;
      width: 1.4em;
    }

    /* ---------- 主体内容：下面的白色区域 ---------- */
    .content-wrapper {
      max-width: var(--max-width);
      margin: 0 auto 60px;
      padding: 0 16px 40px;
    }

    .content-card {
      background: var(--card-bg);
      border-radius: 24px 24px 24px 24px;
      padding: 28px 26px 32px;
      box-shadow: 0 -4px 20px rgba(15, 23, 42, 0.08);
      border: 1px solid rgba(148, 163, 184, 0.4);
    }

    @media (max-width: 640px) {
      .content-card {
        padding: 22px 16px 28px;
      }
    }

    .section {
      margin-bottom: 26px;
    }

    .section:last-of-type {
      margin-bottom: 0;
    }

    .section h2 {
      font-size: 1.25rem;
      margin-bottom: 8px;
      text-align: left;
    }

    .section h3 {
      font-size: 1.05rem;
      margin: 10px 0 4px;
    }

    .section p {
      font-size: 0.96rem;
      color: var(--text-sub);
      text-align: justify;
      margin-bottom: 6px;
    }

    .section ul {
      font-size: 0.94rem;
      color: var(--text-sub);
      margin-left: 20px;
      margin-top: 4px;
    }

    .section li {
      margin-bottom: 4px;
    }

    .badge-row {
      display: flex;
      flex-wrap: wrap;
      gap: 6px;
      margin: 4px 0 6px;
    }

    .badge {
      font-size: 0.8rem;
      padding: 3px 8px;
      border-radius: 999px;
      background: #e0ecff;
      color: #1d4ed8;
      border: 1px solid rgba(129, 140, 248, 0.6);
    }

    .dataset-table {
      width: 100%;
      border-collapse: collapse;
      font-size: 0.85rem;
      margin-top: 6px;
    }

    .dataset-table th,
    .dataset-table td {
      border: 1px solid var(--border);
      padding: 4px 6px;
      text-align: left;
    }

    .dataset-table th {
      background: #f3f4ff;
      font-weight: 600;
    }

    .highlight {
      margin-top: 6px;
      font-size: 0.86rem;
      background: #e0f2fe;
      border-radius: 10px;
      padding: 6px 8px;
      color: #0f172a;
    }

    pre {
      background: #020617;
      color: #e5e7eb;
      padding: 10px 12px;
      border-radius: 12px;
      overflow-x: auto;
      font-size: 0.8rem;
      border: 1px solid rgba(30, 64, 175, 0.8);
    }

    code {
      font-family: ui-monospace, SFMono-Regular, Menlo, Monaco, Consolas,
        "Liberation Mono", "Courier New", monospace;
    }

    footer {
      max-width: var(--max-width);
      margin: 0 auto 30px;
      padding: 10px 16px 0;
      font-size: 0.8rem;
      color: var(--text-sub);
      display: flex;
      justify-content: space-between;
      gap: 8px;
      flex-wrap: wrap;
    }

    html {
      scroll-behavior: smooth;
    }
    /* —— 三个手机截图排成一排 —— */
.device-row {
  max-width: 1000px;        /* 整块区域的最大宽度 */
  margin: 20px auto 0;      /* 居中 + 和上面内容留点空 */
  display: flex;
  flex-wrap: wrap;          /* 屏幕窄的时候自动换行 */
  justify-content: center;  /* 居中对齐 */
  gap: 20px;                /* 图片之间的间距 */
}

/* —— 单张手机截图的样式 —— */
.device-shot {
  display: block;
  width: 100%;
  max-width: 260px;         /* 每张图看起来多宽，可以改成 230 / 280 */
  border-radius: 26px;      /* 圆角，模拟手机壳边缘 */
  box-shadow: 0 20px 40px rgba(15, 23, 42, 0.35);  /* 投影 */
  background: #000;         /* 防止截图白边，看起来更扎实 */
}

/* 小屏幕时略微缩小一点 */
@media (max-width: 640px) {
  .device-shot {
    max-width: 220px;
  }
}
    /* 按钮里的小 logo 图标 */
.btn-icon-img {
  width: 20px;
  height: 20px;
  margin-right: 6px;
  display: inline-block;
  object-fit: contain;
  vertical-align: middle;
}


  </style>
</head>
<body>

  <!-- ---------- HERO 顶部 ---------- -->
  <header class="hero">
    <div class="hero-inner">
      <h1 class="title">Menta: A Small Language Model for On-Device Mental Health Prediction</h1>

      <div class="authors">
        Tianyi Zhang<sup>1</sup>, Xiangyuan Xue<sup>2</sup>, Lingyan Ruan<sup>1</sup>,
        Shiya Fu<sup>1</sup>, Feng Xia<sup>3</sup>, Simon D'Alfonso<sup>1</sup>,<br />
        Vassilis Kostakos<sup>1</sup>, Ting Dang<sup>1</sup>, Hong Jia<sup>2</sup>
      </div>

      <div class="affiliations">
        <sup>1</sup> The University of Melbourne, Australia &nbsp;·&nbsp;
        <sup>2</sup> The University of Auckland, New&nbsp;Zealand &nbsp;·&nbsp;
        <sup>3</sup> RMIT University, Australia
      </div>

      <div class="btn-row">
  <!-- GitHub 按钮 -->
  <a class="link-btn"
     href="https://github.com/xxue752-nz/Menta"
     target="_blank" rel="noopener noreferrer">
    <img src="11.png"
         alt="GitHub logo"
         class="btn-icon-img" />
    <span>GitHub</span>
  </a>

  <!-- Hugging Face 按钮 -->
  <a class="link-btn"
     href="https://huggingface.co/mHealthAI/Menta"
     target="_blank" rel="noopener noreferrer">
    <img src="12.png"
         alt="Hugging Face logo"
         class="btn-icon-img" />
    <span>Hugging&nbsp;Face</span>
  </a>
</div>

    </div>
  </header>

  <!-- ---------- 主体内容：所有 section ---------- -->
  <main class="content-wrapper">
    <div class="content-card">
      <!-- Abstract -->
      <section id="abstract" class="section">
        <h2>Abstract</h2>
        <p>
          Mental health conditions affect hundreds of millions globally, yet early detection remains limited. While large language models
(LLMs) have shown promise in mental health applications, their size and computational demands hinder practical deployment. Small 
language models (SLMs) offer a lightweight alternative, but their use for social media–based mental health prediction remains largely
underexplored. In this study, we introduce Menta, the first optimized SLM fine-tuned specifically for multi-task mental health prediction
from social media data. Menta is jointly trained across six classification tasks using a LoRA-based framework, a cross-dataset strategy,
and a balanced accuracy–oriented loss. Evaluated against nine state-of-the-art SLM baselines, Menta achieves an average improvement
of 15.2% across tasks covering depression, stress, and suicidality compared with the best-performing non–fine-tuned SLMs. It also
achieves higher accuracy on depression and stress classification tasks compared to 13B-parameter LLMs, while being approximately
3.25× smaller. Moreover, we demonstrate real-time, on-device deployment of Menta on an iPhone 15 Pro Max, requiring only
approximately 3GB RAM. Supported by a comprehensive benchmark against existing SLMs and LLMs, Menta highlights the potential
for scalable, privacy-preserving mental health monitoring.
          <img src="3.png" alt="main" style="display:block;width:100%;max-width:850px;margin:20px auto 8px;border-radius:18px;"/>
        </p>
      </section>

      <!-- 1. Overview -->
      <section class="section">
        <h2>1. Overview</h2>
        <p>
          Menta is a small language model for digital mental health prediction from social media text.
          Instead of relying on large server-side LLMs, Menta focuses on early screening of stress,
          depression, and suicidality in a way that is lightweight enough to run fully on consumer
          devices such as smartphones.
        </p>
        <p>
          The model is jointly trained on six Reddit-based classification tasks that cover stress,
          depression severity, suicidal ideation, and suicide risk categories. This multi-task setup
          encourages shared representations across related conditions while preserving task-specific
          decision boundaries.
        </p>
        <ul>
          <li>4B-parameter small language model with a Qwen-style backbone.</li>
          <li>Six mental health classification tasks collected from expert-annotated Reddit corpora.</li>
          <li>LoRA-based multi-task fine-tuning for efficient adaptation.</li>
          <li>Balanced-accuracy–aware optimization to handle imbalanced labels.</li>
          <li>
            Demonstrated real-time on-device deployment for privacy-preserving mental health screening.
          </li>
        </ul>
      </section>

      <!-- 2. Model & Training -->
      <section id="model" class="section">
        <h2>2. Model and Training</h2>
        <p>
          Menta is built on top of a 4B-parameter transformer-based small language model and fine-tuned
          with parameter-efficient LoRA adapters for multi-task mental health prediction. The base model
          remains mostly frozen while LoRA layers capture task-specific adaptations.
        </p>

        <div class="badge-row">
          <span class="badge">4B SLM backbone</span>
          <span class="badge">LoRA adapters</span>
          <span class="badge">Multi-task training</span>
          <span class="badge">Balanced-accuracy loss</span>
        </div>

        <p>
          The training pipeline uses a shared transformer backbone with task-specific classification
          heads. LoRA adapters are inserted into attention projections (e.g., query and value
          matrices), enabling effective fine-tuning while updating only a small fraction of the total
          parameters.
        </p>
        <ul>
          <li>
            <strong>Parameter-efficient tuning.</strong> Only LoRA parameters and classifier heads are
            trained; base model weights are frozen, substantially reducing GPU memory requirements.
          </li>
          <li>
            <strong>Task sampling.</strong> A task-level sampling strategy mitigates dataset size
            imbalance, preventing large datasets from dominating the multi-task objective.
          </li>
          <li>
            <strong>Class imbalance handling.</strong> Class-weighted cross-entropy and a
            balanced-accuracy–aware term are combined to encourage robust performance on minority
            classes.
          </li>
          <li>
            <strong>Joint optimization.</strong> All six tasks are optimized in a single training run,
            encouraging the model to share knowledge across stress, depression, and suicidality
            detection.
          </li>
        </ul>
      </section>

      <!-- 3. Results -->
      <section id="results" class="section">
        <h2>3. Evaluation and Results</h2>
        <p>
          We compare Menta against a range of baselines, including zero-shot and few-shot prompting
          with general-purpose small language models, as well as larger mental-health–tuned LLMs.
        </p>
        <ul>
          <li>
            Menta consistently outperforms non-fine-tuned small language models on all six tasks,
            demonstrating the value of dedicated mental-health fine-tuning.
          </li>
          <li>
            On depression and stress prediction, Menta achieves performance that is competitive with
            or superior to 13B-parameter mental-health–tuned LLMs, despite being substantially smaller.
          </li>
          <li>
            The 4B model is much more suitable for on-device deployment than 13B LLMs in terms of both
            memory footprint and latency.
          </li>
        </ul>
        <p class="highlight">
          <img src="5.png" alt="5" style="display:block;width:100%;max-width:850px;margin:20px auto 8px;border-radius:18px;"/>
        </p>
      </section>

      <!-- Datasets -->
      <section id="datasets" class="section">
        <h2>4. Datasets</h2>
        <p>
          Menta is trained and evaluated on four expert-annotated Reddit corpora, organized into six
          classification tasks that cover stress, depression, suicidal ideation, and suicide risk.
        </p>

        <table class="dataset-table">
          <thead>
            <tr>
              <th>Task</th>
              <th>Dataset</th>
              <th>Label type</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>Task&nbsp;1</td>
              <td>Dreaddit</td>
              <td>Stress vs. non-stress</td>
            </tr>
            <tr>
              <td>Task&nbsp;2–3</td>
              <td>Depression severity dataset</td>
              <td>Binary depression + multi-level severity</td>
            </tr>
            <tr>
              <td>Task&nbsp;4</td>
              <td>SDCNL</td>
              <td>Suicidal ideation vs. non-ideation</td>
            </tr>
            <tr>
              <td>Task&nbsp;5–6</td>
              <td>CSSRS-based suicide risk dataset</td>
              <td>Binary risk + multi-level risk categories</td>
            </tr>
          </tbody>
        </table>

        <p class="highlight">
          <img src="4.png" alt="dataset" style="display:block;width:100%;max-width:850px;margin:20px auto 8px;border-radius:18px;"/>
        </p>
      </section>

      <!-- On-device Deployment -->
      <section id="deployment" class="section">
        <h2>5. On-Device Deployment</h2>
        <p>
          We deploy Menta on mobile devices using a lightweight inference stack with quantized weights.
          The goal is to enable privacy-preserving, real-time mental health screening directly on
          user devices without uploading raw text to remote servers.
        </p>
        <ul>
          <li>
            4-bit GGUF quantization to reduce memory footprint while maintaining task performance.
          </li>
          <li>
            Inference via <code>llama.cpp</code> or a similar engine with Metal acceleration on iOS.
          </li>
          <li>
            Demonstrated deployment on an iPhone&nbsp;15 Pro Max with interactive-level latency and
            moderate memory usage.
          </li>
          <li>
            All processing stays on device, which reduces privacy risks for sensitive mental-health
            texts.
          </li>
        </ul>
        <p class="highlight">
          <div class="device-row">
  <img src="device_demo1.jpg"
       alt="Menta mobile UI – model selection"
       class="device-shot" />

  <img src="device_demo2.jpg"
       alt="Menta mobile UI – task selection"
       class="device-shot" />

  <img src="device_demo3.jpg"
       alt="Menta mobile UI – sample count selection"
       class="device-shot" />
</div>

        </p>
      </section>

      <!-- Implementation / resources -->
      <section class="section">
        <h2>6. Implementation and Resources</h2>
        <p>
          The full training and evaluation code, together with instructions for reproducing our
          experiments and running Menta on mobile devices, is available in the GitHub repository.
          Pre-trained weights and configuration files for different quantization levels are hosted on
          Hugging&nbsp;Face.
        </p>
        <ul>
          <li><strong>GitHub:</strong> end-to-end training, evaluation, and on-device demo code.</li>
          <li><strong>Hugging&nbsp;Face:</strong> model checkpoints and configuration files.</li>
          <li>
            <strong>Mobile demo:</strong> a reference iOS application showing multi-task predictions
            for stress, depression, and suicidality from example posts.
          </li>
        </ul>
      </p>
      </section>
    </div>
  </main>

  <footer>
    <span>© 2025 Menta Authors.</span>
    <span>Code and models for research use only. Please see the repository for license details.</span>
  </footer>

</body>
</html>


